<!doctype html><head><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><link rel=icon type=image/png href=/images/favicon.png><link rel="shortcut icon" type=image/png href=/images/favicon.png><title>Deep Learning Framework in C++ - Valen Yamamoto</title><meta name=author content="Valen Yamamoto"><meta name=description content="Welcome to my portfolio!"><meta name=keywords content="Machine Learning,C++"><meta property="og:title" content="Deep Learning Framework in C++"><meta property="og:description" content="Github Repository
Ever since I started learning PyTorch, I have been fascinated by the automatic gradient feature. In order to further understand it, I decided I would try to write my own version. At the time, I was also taking a C++ class, so I decided to both learn about autograd and study for my finals. (As well as do the required project to initiate into IEEE-HKN)
This program dynamically constructs a computation graph as operations are done."><meta property="og:type" content="article"><meta property="og:url" content="https://ValenYamamoto.github.io/2020/12/deep-learning-framework-in-c-/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-12-08T17:38:57-07:00"><meta property="article:modified_time" content="2020-12-08T17:38:57-07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Deep Learning Framework in C++"><meta name=twitter:description content="Github Repository
Ever since I started learning PyTorch, I have been fascinated by the automatic gradient feature. In order to further understand it, I decided I would try to write my own version. At the time, I was also taking a C++ class, so I decided to both learn about autograd and study for my finals. (As well as do the required project to initiate into IEEE-HKN)
This program dynamically constructs a computation graph as operations are done."><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css><link rel=stylesheet href=https://ValenYamamoto.github.io/scss/main.min.9c5016003fb3e2286e67eda660350dca36c0001d93a823539298998741df062b.css integrity="sha256-nFAWAD+z4ihuZ+2mYDUNyjbAAB2TqCNTkpiZh0HfBis=" crossorigin=anonymous media=screen><link href=//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css rel=stylesheet></head></head><body><span class="mobile btn-mobile-menu"><i class="fa fa-list btn-mobile-menu__icon"></i>
<i class="fa fa-angle-up btn-mobile-close__icon hidden"></i></span><header class="panel-cover panel-cover--collapsed" style=background-image:url(/images/background-cover.jpg)><div class=panel-main><div class="panel-main__inner panel-inverted"><div class=panel-main__content><a href=/#blog title="Homepage of Valen Yamamoto " class=blog-button><img src=/images/avatar.jpg width=80 alt="Valen Yamamoto logo" class="panel-cover__logo logo"></a><h1 class="panel-cover__title panel-title"><a href=/#blog title="Homepage of Valen Yamamoto" class=blog-button>Valen Yamamoto</a></h1><span class="panel-cover__subtitle panel-subtitle">CS Student @ UCI</span><hr class=panel-cover__divider><p class=panel-cover__description>Welcome to my portfolio!</p><hr class="panel-cover__divider panel-cover__divider--secondary"><p class=panel-cover__description>Hi! I am a computer science student at the University of California, Irvine specializing in machine learning, robotics algorithms, and optimizing parallel algorithms for high performance environments</p><div class=navigation-wrapper><div><nav class="cover-navigation cover-navigation--primary"><ul class=navigation><li class=navigation__item><a href=/#blog title=Blog class=blog-button>Blog</a></li></ul></nav></div><div><nav class="cover-navigation navigation--social"><ul class=navigation><li class=navigation__item><a href=https://github.com/ValenYamamoto title=@ValenYamamoto target=_blank><i class='social fa fa-github'></i>
<span class=label>Github</span></a></li><li class=navigation__item><a href=https://www.linkedin.com/in/ValenYamamoto title=@ValenYamamoto target=_blank><i class='social fa fa-linkedin'></i>
<span class=label>Linkedin</span></a></li><li class=navigation__item><a href=/index.xml rel=author title=RSS target=_blank><i class='social fa fa-rss'></i>
<span class=label>RSS</span></a></li><li class=navigation__item><a href=mailto:vyamamot@uci.edu title="Contact me"><i class='social fa fa-envelope'></i>
<span class=label>Email</span></a></li></ul></nav></div></div></div></div><div class="panel-cover--overlay cover-blue"></div></div></header><div class=content-wrapper><div class=content-wrapper__inner><article class="post-container post-container--single" itemscope itemtype=http://schema.org/BlogPosting><header class=post-header><div class=post-meta><time datetime=" 2020-12-08 17:38:57 -0700 " itemprop=datePublished class="post-meta__date date">2020-12-08</time>
<span class="post-meta__tags tags">• <a href=https://ValenYamamoto.github.io/tags/machine-learning>Machine Learning</a> • <a href=https://ValenYamamoto.github.io/tags/c++>C++</a></span></div><h1 class=post-title>Deep Learning Framework in C++</h1></header><section class=post><p><a href=https://github.com/ValenYamamoto/DeepLearningFramework>Github Repository</a></p><p>Ever since I started learning PyTorch, I have been fascinated by the automatic
gradient feature. In order to further understand it, I decided I would try to
write my own version. At the time, I was also taking a C++ class, so I decided
to both learn about autograd and study for my finals. (As well as do the
required project to initiate into IEEE-HKN)</p><p>This program dynamically constructs a computation graph as operations are done.
When the backward function is called on the final node, then, just as in
PyTorch, all the gradients are calculated for all the intermediate nodes.</p><p>Currently, this program only supports linear layers. For non-linear activation
functions, the program requires that both the function and a function for its
derivative/gradient are passed in. I included a Sequential wrapper, which does
exactly what it does in PyTorch. Even those I wrote these layer abstraction, the
automatic differentiation still works for math done outside layers.</p><p>The current mathematical operations this program supports are:</p><ul><li>Elementwise addition, subtraction, mulitplication</li><li>Matrix multiplication</li><li>Reduce sum</li></ul><p>Because I also did this project to strengthen my C++ skills, this project tries
to knock off most of the basic, object-oriented C++ skills:</p><ul><li>Classes - All layers and tensors are implemented as classes, as well as my SGD
implementation</li><li>Polymorphism and Inheritence - Layer classes all descend from an abstract base
class and overload the forward method, just as they do in PyTorch</li><li>Operator Overloading - Since the dynamic computation graph is built as
operations are done on tensors, I have overloaded the basic operators
(+,-,*,/) to add to the graph when executed</li><li>Functions and Lambdas - Activation functions and their derivatives need to be passed
in when being used, and they can either be written traditionally as a function
or as a lamdba function</li></ul><p>This project also gave me the opportunity to practice other coding related
skills, including:</p><ul><li>Makefiles - I wrote my own Makefile for this project to compile both
executables and intermediate object files</li><li>Memory Check - I used valgrind to check for memory leaks and uninitialized
memory reads</li></ul></section></article><section class=read-more><div class=read-more-item><span class=read-more-item-dim>Recent</span><h2 class="post-list__post-title post-title"><a href=/2021/04/python-scripts-for-parsing-spice-output-a-workshop/ title="link to Python Scripts for Parsing SPICE Output: A Workshop">Python Scripts for Parsing SPICE Output: A Workshop</a></h2><p class=excerpt>Github Repository
Python is particularly useful for writing quick scripts. I find myself reaching for Python whenever I need to parse output into more readable/processable forms like csv files or pandas DataFrames. Engineering students at UCI …&mldr;</p><div class=post-list__meta><time datetime=" 2020-12-08 17:38:57 -0700" class="post-list__meta--date date">2021-04-23</time>
<span class="post-list__meta--tags tags">• <a href=https://ValenYamamoto.github.io/tags/python>python</a> • <a href=https://ValenYamamoto.github.io/tags/spice>SPICE</a> • <a href=https://ValenYamamoto.github.io/tags/ieee>IEEE</a></span>
<a class=btn-border-small href=/2021/04/python-scripts-for-parsing-spice-output-a-workshop/>Continue</a></div></div><div class=read-more-item><span class=read-more-item-dim>Earlier</span><h2 class="post-list__post-title post-title"><a href=/2020/11/mpi-workshop/ title="link to MPI Workshop">MPI Workshop</a></h2><p class=excerpt>Github Repository
After my internship at Lawrence Livermore National Laboratory, I decided to write on workshop on MPI for parallel programming. As large servers become more ubiquitous in most computer science workplaces, being able to write and …&mldr;</p><div class=post-list__meta><time datetime=" 2020-12-08 17:38:57 -0700" class="post-list__meta--date date">2020-11-12</time>
<span class="post-list__meta--tags tags">• <a href=https://ValenYamamoto.github.io/tags/mpi>MPI</a> • <a href=https://ValenYamamoto.github.io/tags/ieee>IEEE</a></span>
<a class=btn-border-small href=/2020/11/mpi-workshop/>Continue</a></div></div></section><section class=footer><footer><span class=footer__copyright>This site is licensed under a <a href=http://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a> license.</span>
<span class=footer__copyright>Generated by <a href=https://gohugo.io/>Hugo</a> at 2022-10-22, themed with <a href=https://github.com/xslingcn/vno-hugo>Vno - Hugo</a>.</span></footer></section></div></div><script type=text/javascript src=//code.jquery.com/jquery-1.11.3.min.js></script>
<script type=text/javascript src=/js/main.js></script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","your_ga_id","your_host"),ga("send","pageview")</script></body>