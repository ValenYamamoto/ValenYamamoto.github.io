<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Valen Yamamoto</title><link>https://ValenYamamoto.github.io/posts/</link><description>Recent content in Posts on Valen Yamamoto</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 20 Aug 2022 20:46:38 -0700</lastBuildDate><atom:link href="https://ValenYamamoto.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>JPL M2020 Internship</title><link>https://ValenYamamoto.github.io/2022/08/jpl-m2020-internship/</link><pubDate>Sat, 20 Aug 2022 20:46:38 -0700</pubDate><guid>https://ValenYamamoto.github.io/2022/08/jpl-m2020-internship/</guid><description>I worked in Section 374K with Justin Huang implementing RRTConnect has a motion planning algorithm for the the 5 DOF arms on the Mars rovers. Usually in motion planning, paths are smoothed to make corners into curves for less jerky motion; however, for space robotics, planners try to send the least amount of data through space to the rovers so the minimal number of viapoints is preferred. So instead of smoothing the RRT-generated paths, I spent the majority of my time simplifying the paths to the smallest number of viapoints.</description></item><item><title>Machine Learning Internship @ LLNL</title><link>https://ValenYamamoto.github.io/2021/11/machine-learning-internship-llnl/</link><pubDate>Sat, 20 Nov 2021 20:46:33 -0700</pubDate><guid>https://ValenYamamoto.github.io/2021/11/machine-learning-internship-llnl/</guid><description>My second summer internship at Lawrence Livermore National Laboratory (LLNL) focused on comparing machine learning inference performance on novel AI hardware accelerators from Samba Nova and Cerebras to NVIDIA GPUs. I was working with a autoencoder model used to material interface reconstruction (MIR) for multi-material hydrodynamics codes. The neural network was proposed as an alternative to current solution PLIC: the neural network provided much smoother, continuous boundaries than PLIC, which could only give linear approximations.</description></item><item><title>Python Scripts for Parsing SPICE Output: A Workshop</title><link>https://ValenYamamoto.github.io/2021/04/python-scripts-for-parsing-spice-output-a-workshop/</link><pubDate>Fri, 23 Apr 2021 20:46:17 -0700</pubDate><guid>https://ValenYamamoto.github.io/2021/04/python-scripts-for-parsing-spice-output-a-workshop/</guid><description>Github Repository
Python is particularly useful for writing quick scripts. I find myself reaching for Python whenever I need to parse output into more readable/processable forms like csv files or pandas DataFrames. Engineering students at UCI don&amp;rsquo;t spend a lot of time learning Python, so I thought this would be a particularly useful exercise.
This workshop goes through a program to parse PSPICE output and allows the user to either output a csv version of the output or to pick out particular components with voltages or currents above a specified threshold.</description></item><item><title>MPI Workshop</title><link>https://ValenYamamoto.github.io/2020/11/mpi-workshop/</link><pubDate>Thu, 12 Nov 2020 20:46:03 -0700</pubDate><guid>https://ValenYamamoto.github.io/2020/11/mpi-workshop/</guid><description>Github Repository
After my internship at Lawrence Livermore National Laboratory, I decided to write on workshop on MPI for parallel programming. As large servers become more ubiquitous in most computer science workplaces, being able to write and execute multi-processor programs becomes more useful and feasible.
This workshop covers the following concepts:
blocking/non-blocking sends/receives openMPI for C mpi4py for Python buffers Collective Communication Routinues This workshop also has some Google Colab notebooks for participants to follow along with:</description></item><item><title>HPCCEA Internship @ LLNL</title><link>https://ValenYamamoto.github.io/2020/08/hpccea-internship-llnl/</link><pubDate>Thu, 20 Aug 2020 20:46:28 -0700</pubDate><guid>https://ValenYamamoto.github.io/2020/08/hpccea-internship-llnl/</guid><description>For my first internship, I worked at the Lawrence Livermore National Laboratory (LLNL) as a part of the High Performance Computing Cluster Engineering Academy (HPCCEA) program. As a part of this program, I got to experience how the computing division of one the world&amp;rsquo;s pioneering supercomputing centers was run. I worked on installing computing nodes, writing bash scripts and eventually using Ansible to automate the proces of bring up a new node.</description></item></channel></rss>